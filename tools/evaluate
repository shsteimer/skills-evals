#!/usr/bin/env node

/**
 * Evaluation Script for Agent Skills Tests
 *
 * Usage:
 *   ./tools/evaluate <output-dir> [options]
 *
 * Arguments:
 *   <output-dir>          Path to test results directory
 *
 * Options:
 *   --eval-agent <agent>  Agent to use for non-deterministic evaluation (default: claude-code)
 *   --skip-non-deterministic       Only run deterministic checks (faster)
 *   --help                Show this help message
 */

import { readFileSync, writeFileSync, existsSync, readdirSync, statSync } from 'fs';
import { join, dirname, basename, relative } from 'path';
import { fileURLToPath } from 'url';
import { execSync, spawnSync } from 'child_process';
import { parse as parseYaml } from 'yaml';

const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);
const PROJECT_ROOT = join(__dirname, '..');

/**
 * Parse command line arguments
 */
function parseArgs() {
  const args = process.argv.slice(2);

  if (args.includes('--help') || args.length === 0) {
    showHelp();
    process.exit(0);
  }

  const options = {
    outputDir: null,
    evalAgent: 'claude-code',
    skipNonDeterministic: false
  };

  let i = 0;
  while (i < args.length) {
    const arg = args[i];
    const next = args[i + 1];

    switch (arg) {
      case '--eval-agent':
        options.evalAgent = next || 'claude-code';
        i++;
        break;
      case '--skip-non-deterministic':
      case '--skip-flexible': // Backward compatibility
        options.skipNonDeterministic = true;
        break;
      default:
        if (!options.outputDir && !arg.startsWith('--')) {
          options.outputDir = arg;
        }
        break;
    }
    i++;
  }

  if (!options.outputDir) {
    console.error('Error: Output directory is required');
    showHelp();
    process.exit(1);
  }

  if (!existsSync(options.outputDir)) {
    console.error(`Error: Output directory does not exist: ${options.outputDir}`);
    process.exit(1);
  }

  return options;
}

/**
 * Show help message
 */
function showHelp() {
  console.log(`
Evaluation Script for Agent Skills Tests

Usage:
  ./tools/evaluate <output-dir> [options]

Arguments:
  <output-dir>          Path to test results directory

Options:
  --eval-agent <agent>  Agent to use for non-deterministic evaluation (default: claude-code)
  --skip-non-deterministic  Only run deterministic checks (faster)
  --help                Show this help message

Examples:
  # Run full evaluation
  ./tools/evaluate test-results/tests/unit/building-blocks/create-simple-block/2025-01-14T10:00:00Z/claude-code

  # Skip non-deterministic evaluation (deterministic only)
  ./tools/evaluate <output-dir> --skip-non-deterministic

  # Use specific agent for non-deterministic evaluation
  ./tools/evaluate <output-dir> --eval-agent cursor-cli
`);
}

/**
 * Load test definition from test.yaml
 */
function loadTestDefinition(outputDir) {
  // Output dir structure can be:
  // - test-results/<test-path>/<timestamp>/<agent>/  (specific agent)
  // - test-results/<test-path>/<timestamp>/          (all agents)
  // We need to find the test.yaml in tests/<test-path>/test.yaml

  const parts = outputDir.split('/');
  const testResultsIndex = parts.indexOf('test-results');

  if (testResultsIndex === -1) {
    throw new Error('Output directory must be under test-results/');
  }

  // Extract test path (everything between test-results and timestamp)
  // If path ends with timestamp (not agent), it's 1 fewer part
  const isTimestampDir = outputDir.match(/\d{4}-\d{2}-\d{2}T[\d:.]+Z\/?$/);
  const offset = isTimestampDir ? 1 : 2;

  const testPathParts = [];
  for (let i = testResultsIndex + 1; i < parts.length - offset; i++) {
    testPathParts.push(parts[i]);
  }

  const testPath = join(PROJECT_ROOT, ...testPathParts, 'test.yaml');

  if (!existsSync(testPath)) {
    throw new Error(`Test definition not found: ${testPath}`);
  }

  const content = readFileSync(testPath, 'utf8');
  return parseYaml(content);
}

/**
 * Detect if path is a timestamp directory (contains agent subdirs) or specific agent directory
 */
function detectPathType(outputDir) {
  // Check if path ends with timestamp pattern
  if (outputDir.match(/\d{4}-\d{2}-\d{2}T[\d:.]+Z\/?$/)) {
    return 'timestamp';
  }
  return 'agent';
}

/**
 * Get all agent directories in a timestamp directory
 */
function getAgentDirectories(timestampDir) {
  try {
    const entries = readdirSync(timestampDir);
    return entries.filter(entry => {
      const fullPath = join(timestampDir, entry);
      const stat = statSync(fullPath);
      return stat.isDirectory();
    }).map(dir => join(timestampDir, dir));
  } catch (error) {
    throw new Error(`Failed to read agent directories: ${error.message}`);
  }
}

/**
 * Run deterministic checks (required)
 */
async function runDeterministicChecks(outputDir, testDef) {
  console.log('\n=== Running Deterministic Checks ===\n');

  const results = {
    passed: true,
    failures: [],
    checks: {}
  };

  const checks = testDef.deterministic_checks || {};

  // Check if required files exist (check in git diff)
  if (checks.files_exist) {
    console.log('Checking required files...');

    // Read the code diff to see what files were created/modified
    const diffPath = join(outputDir, 'code-diff.patch');
    let diffContent = '';
    if (existsSync(diffPath)) {
      diffContent = readFileSync(diffPath, 'utf8');
    }

    for (const file of checks.files_exist) {
      // Check if file appears in the diff (as a new or modified file)
      const fileInDiff = diffContent.includes(`+++ b/${file}`) || diffContent.includes(`diff --git a/${file}`);
      results.checks[`file_exists:${file}`] = fileInDiff;

      if (!fileInDiff) {
        results.passed = false;
        results.failures.push(`Required file does not exist: ${file}`);
        console.log(`  ✗ ${file} (MISSING)`);
      } else {
        console.log(`  ✓ ${file}`);
      }
    }
  }

  // Check if files should NOT exist
  if (checks.files_not_exist) {
    console.log('\nChecking files that should not exist...');

    // Read the code diff to see what files were created/modified
    const diffPath = join(outputDir, 'code-diff.patch');
    let diffContent = '';
    if (existsSync(diffPath)) {
      diffContent = readFileSync(diffPath, 'utf8');
    }

    for (const file of checks.files_not_exist) {
      // Check if file appears in the diff
      const fileInDiff = diffContent.includes(`+++ b/${file}`) || diffContent.includes(`diff --git a/${file}`);
      results.checks[`file_not_exists:${file}`] = !fileInDiff;

      if (fileInDiff) {
        results.passed = false;
        results.failures.push(`File should not exist: ${file}`);
        console.log(`  ✗ ${file} (EXISTS)`);
      } else {
        console.log(`  ✓ ${file} (correctly absent)`);
      }
    }
  }

  // Check linting results if required
  if (checks.lint_passes) {
    console.log('\nChecking linting results...');
    const lintResultPath = join(outputDir, 'lint-result.json');

    if (existsSync(lintResultPath)) {
      try {
        const lintResult = JSON.parse(readFileSync(lintResultPath, 'utf8'));
        results.checks['lint_passes'] = lintResult.passed;

        if (lintResult.passed) {
          console.log('  ✓ Linting passed');
        } else {
          results.passed = false;
          results.failures.push('Linting failed');
          console.log('  ✗ Linting failed');
          // Show first few lines of lint output
          if (lintResult.output) {
            const lines = lintResult.output.split('\n').slice(0, 10);
            lines.forEach(line => console.log(`    ${line}`));
            if (lintResult.output.split('\n').length > 10) {
              console.log('    ... (see lint-output.txt for full output)');
            }
          }
        }
      } catch (e) {
        console.log(`  ⚠ Could not parse lint results: ${e.message}`);
        results.checks['lint_passes'] = false;
      }
    } else {
      console.log('  ⚠ Lint results not found (linting may not have run)');
      results.checks['lint_passes'] = false;
    }
  }

  // Check for forbidden patterns
  if (checks.forbidden_patterns) {
    console.log('\nChecking for forbidden patterns...');

    // Read the code diff
    const diffPath = join(outputDir, 'code-diff.patch');
    let diffContent = '';
    if (existsSync(diffPath)) {
      diffContent = readFileSync(diffPath, 'utf8');
    }

    for (const check of checks.forbidden_patterns) {
      const pattern = check.pattern;
      const inFiles = check.in_files || ['**/*'];

      // Search for pattern in added lines (lines starting with +) in the diff
      let found = false;
      const foundIn = [];

      // Split diff into file sections
      const fileSections = diffContent.split(/^diff --git /m).slice(1);

      for (const section of fileSections) {
        const fileMatch = section.match(/^a\/(.+?) b\/(.+?)$/m);
        if (!fileMatch) continue;

        const fileName = fileMatch[2];

        // Check if file matches any of the globs
        const matchesGlob = inFiles.some(glob => {
          if (glob === '**/*') return true;
          // Simple glob matching (could be improved with a proper glob library)
          const globRegex = new RegExp('^' + glob.replace(/\*/g, '.*').replace(/\?/g, '.') + '$');
          return globRegex.test(fileName);
        });

        if (!matchesGlob) continue;

        // Extract added lines (lines starting with +, but not +++)
        const lines = section.split('\n');
        for (const line of lines) {
          if (line.startsWith('+') && !line.startsWith('+++')) {
            // Check if pattern exists in this added line
            const regex = new RegExp(pattern);
            if (regex.test(line)) {
              found = true;
              if (!foundIn.includes(fileName)) {
                foundIn.push(fileName);
              }
            }
          }
        }
      }

      if (found) {
        results.passed = false;
        results.failures.push(`Forbidden pattern found: "${pattern}" in ${foundIn.join(', ')}`);
        results.checks[`forbidden_pattern:${pattern}`] = false;
        console.log(`  ✗ Pattern "${pattern}" found in:`);
        foundIn.forEach(f => console.log(`    - ${f}`));
      } else {
        results.checks[`forbidden_pattern:${pattern}`] = true;
        console.log(`  ✓ Pattern "${pattern}" not found`);
      }
    }
  }

  // Check for required patterns
  if (checks.required_patterns) {
    console.log('\nChecking for required patterns...');

    // Read the code diff
    const diffPath = join(outputDir, 'code-diff.patch');
    let diffContent = '';
    if (existsSync(diffPath)) {
      diffContent = readFileSync(diffPath, 'utf8');
    }

    for (const check of checks.required_patterns) {
      const pattern = check.pattern;
      const inFiles = check.in_files || ['**/*'];

      // Search for pattern in added lines
      let found = false;
      const foundIn = [];

      const fileSections = diffContent.split(/^diff --git /m).slice(1);

      for (const section of fileSections) {
        const fileMatch = section.match(/^a\/(.+?) b\/(.+?)$/m);
        if (!fileMatch) continue;

        const fileName = fileMatch[2];

        const matchesGlob = inFiles.some(glob => {
          if (glob === '**/*') return true;
          const globRegex = new RegExp('^' + glob.replace(/\*/g, '.*').replace(/\?/g, '.') + '$');
          return globRegex.test(fileName);
        });

        if (!matchesGlob) continue;

        const lines = section.split('\n');
        for (const line of lines) {
          if (line.startsWith('+') && !line.startsWith('+++')) {
            const regex = new RegExp(pattern);
            if (regex.test(line)) {
              found = true;
              if (!foundIn.includes(fileName)) {
                foundIn.push(fileName);
              }
            }
          }
        }
      }

      if (!found) {
        results.passed = false;
        results.failures.push(`Required pattern not found: "${pattern}"`);
        results.checks[`required_pattern:${pattern}`] = false;
        console.log(`  ✗ Pattern "${pattern}" not found`);
      } else {
        results.checks[`required_pattern:${pattern}`] = true;
        console.log(`  ✓ Pattern "${pattern}" found in ${foundIn.join(', ')}`);
      }
    }
  }

  // Run custom scripts if specified
  if (checks.custom_scripts) {
    console.log('\nRunning custom scripts...');

    for (const script of checks.custom_scripts) {
      const scriptName = script.name || script.script;
      const scriptCommand = script.script;
      const workingDir = script.cwd || outputDir;

      console.log(`  Running: ${scriptName}`);

      try {
        const result = spawnSync('bash', ['-c', scriptCommand], {
          cwd: workingDir,
          encoding: 'utf8',
          stdio: 'pipe',
          timeout: script.timeout || 30000
        });

        const passed = result.status === 0;
        results.checks[`custom_script:${scriptName}`] = passed;

        if (passed) {
          console.log(`    ✓ ${scriptName} passed`);
        } else {
          results.passed = false;
          results.failures.push(`Custom script failed: ${scriptName}`);
          console.log(`    ✗ ${scriptName} failed`);
          if (result.stderr) {
            const lines = result.stderr.split('\n').slice(0, 5);
            lines.forEach(line => console.log(`      ${line}`));
          }
        }
      } catch (error) {
        results.passed = false;
        results.failures.push(`Custom script error: ${scriptName} - ${error.message}`);
        results.checks[`custom_script:${scriptName}`] = false;
        console.log(`    ✗ ${scriptName} error: ${error.message}`);
      }
    }
  }

  return results;
}

/**
 * Run optional deterministic checks
 */
async function runOptionalChecks(outputDir, testDef) {
  console.log('\n=== Running Optional Checks ===\n');

  const results = {
    warnings: [],
    checks: {}
  };

  const checks = testDef.optional_checks || {};

  // Optional file checks
  if (checks.files_exist) {
    console.log('Checking optional files...');
    for (const file of checks.files_exist) {
      const filePath = join(outputDir, file);
      const exists = existsSync(filePath);
      results.checks[`optional_file:${file}`] = exists;

      if (!exists) {
        results.warnings.push(`Optional file does not exist: ${file}`);
        console.log(`  ⚠ ${file} (missing but optional)`);
      } else {
        console.log(`  ✓ ${file}`);
      }
    }
  }

  return results;
}

/**
 * Check PR quality if PR was opened
 */
async function checkPRQuality(outputDir, testDef) {
  console.log('\n=== Checking PR Quality ===\n');

  const results = {
    pr_opened: false,
    pr_url: null,
    pr_quality: {},
    failures: []
  };

  // Try to detect PR from git branch
  try {
    // Get the branch name from the output directory
    // The test was run in an isolated branch
    const agentInfoPath = join(outputDir, 'agent-info.json');
    let branchName = null;

    if (existsSync(agentInfoPath)) {
      const agentInfo = JSON.parse(readFileSync(agentInfoPath, 'utf8'));
      branchName = agentInfo.branch;
    }

    if (!branchName) {
      console.log('  ℹ Could not determine branch name');
      console.log('  ℹ No PR opened (no penalty)');
      return results;
    }

    // Check if a PR exists for this branch using gh CLI
    try {
      const prListResult = spawnSync('gh', ['pr', 'list', '--head', branchName, '--json', 'url,number,state'], {
        cwd: PROJECT_ROOT,
        encoding: 'utf8',
        stdio: 'pipe'
      });

      if (prListResult.status === 0 && prListResult.stdout.trim()) {
        const prs = JSON.parse(prListResult.stdout);
        if (prs && prs.length > 0) {
          const pr = prs[0];
          results.pr_opened = true;
          results.pr_url = pr.url;
          console.log(`  ✓ PR detected: ${pr.url}`);

          // Run quality checks if PR was opened
          const checks = testDef.pr_quality_checks || {};

          // Check CI/CD status
          if (checks.checks_pass !== false) {
            console.log('\n  Checking CI/CD status...');
            const checksResult = spawnSync('gh', ['pr', 'checks', pr.number.toString()], {
              cwd: PROJECT_ROOT,
              encoding: 'utf8',
              stdio: 'pipe'
            });

            if (checksResult.status === 0) {
              const output = checksResult.stdout;
              // Parse check results - if any failed, mark as failure
              const failedChecks = output.split('\n').filter(line => line.includes('fail'));
              if (failedChecks.length > 0) {
                results.pr_quality.checks_pass = false;
                results.failures.push('PR has failing checks');
                console.log('    ✗ Some checks failed');
                failedChecks.forEach(check => console.log(`      - ${check.trim()}`));
              } else {
                results.pr_quality.checks_pass = true;
                console.log('    ✓ All checks passing');
              }
            }
          }

          // Check for preview link in PR body
          if (checks.has_preview_link !== false) {
            console.log('\n  Checking for preview link...');
            const prViewResult = spawnSync('gh', ['pr', 'view', pr.number.toString(), '--json', 'body'], {
              cwd: PROJECT_ROOT,
              encoding: 'utf8',
              stdio: 'pipe'
            });

            if (prViewResult.status === 0) {
              const prData = JSON.parse(prViewResult.stdout);
              const body = prData.body || '';

              // Look for preview links (*.aem.page URLs)
              const previewLinkMatch = body.match(/https?:\/\/[a-zA-Z0-9-]+--[a-zA-Z0-9-]+--[a-zA-Z0-9-]+\.aem\.(page|live)/);
              if (previewLinkMatch) {
                results.pr_quality.has_preview_link = true;
                results.pr_quality.preview_url = previewLinkMatch[0];
                console.log(`    ✓ Preview link found: ${previewLinkMatch[0]}`);
              } else {
                results.pr_quality.has_preview_link = false;
                results.failures.push('PR missing preview link');
                console.log('    ✗ No preview link found');
              }
            }
          }

          // Check if preview link is valid (optional, can be slow)
          if (checks.preview_valid !== false && results.pr_quality.preview_url) {
            console.log('\n  Checking preview link validity...');
            try {
              const curlResult = spawnSync('curl', ['-I', '-s', '-o', '/dev/null', '-w', '%{http_code}', results.pr_quality.preview_url], {
                encoding: 'utf8',
                stdio: 'pipe',
                timeout: 10000
              });

              const statusCode = parseInt(curlResult.stdout.trim());
              if (statusCode >= 200 && statusCode < 400) {
                results.pr_quality.preview_valid = true;
                console.log(`    ✓ Preview link returns ${statusCode}`);
              } else {
                results.pr_quality.preview_valid = false;
                results.failures.push(`Preview link returns ${statusCode}`);
                console.log(`    ✗ Preview link returns ${statusCode}`);
              }
            } catch (error) {
              results.pr_quality.preview_valid = false;
              results.failures.push('Preview link check timed out or failed');
              console.log('    ✗ Could not validate preview link');
            }
          }

        } else {
          console.log('  ℹ No PR found for this branch');
          console.log('  ℹ No PR opened (no penalty)');
        }
      }
    } catch (error) {
      console.log('  ℹ Error checking for PR (gh CLI might not be available)');
      console.log(`  ℹ ${error.message}`);
    }

  } catch (error) {
    console.log('  ℹ Error in PR quality check');
    console.log(`  ℹ ${error.message}`);
  }

  return results;
}

/**
 * Run non-deterministic criteria evaluation with LLM
 */
async function runNonDeterministicEvaluation(outputDir, testDef, evalAgent) {
  console.log('\n=== Running Non-Deterministic Criteria Evaluation ===\n');
  console.log(`Using agent: ${evalAgent}\n`);

  const results = {
    by_priority: {
      high: {},
      medium: {},
      low: {}
    },
    overall_notes: []
  };

  const criteria = testDef.non_deterministic_criteria || testDef.flexible_criteria || []; // Support old name

  if (criteria.length === 0) {
    console.log('  ℹ No non-deterministic criteria defined');
    return results;
  }

  console.log(`Evaluating ${criteria.length} criteria...\n`);

  try {
    // Build evaluation prompt
    const prompt = buildEvaluationPrompt(outputDir, testDef, criteria);

    // Save prompt to file for reference
    const promptPath = join(outputDir, 'evaluation-prompt.txt');
    writeFileSync(promptPath, prompt);
    console.log(`  ℹ Saved evaluation prompt: ${promptPath}`);

    // Run evaluation agent
    console.log(`  ℹ Running ${evalAgent} for evaluation...\n`);

    const evalResultPath = join(outputDir, 'evaluation-response.json');
    const evalPromptFile = join(outputDir, 'eval-task.txt');

    // Create a structured task for the agent
    const agentTask = `${prompt}

IMPORTANT: You must respond with ONLY a valid JSON object matching this schema:
{
  "by_priority": {
    "high": {
      "<criterion_name>": {
        "strengths": ["string"],
        "issues": ["string"],
        "notes": ["string"]
      }
    },
    "medium": { /* same structure */ },
    "low": { /* same structure */ }
  },
  "overall_notes": ["string"]
}

Do not include any other text before or after the JSON. The response must be valid JSON.`;

    writeFileSync(evalPromptFile, agentTask);

    // Invoke the evaluation agent
    console.log(`  Invoking ${evalAgent} for evaluation...\n`);

    try {
      let agentCommand;
      let agentArgs = [];

      switch (evalAgent) {
        case 'claude-code':
          agentCommand = 'claude';
          agentArgs = [
            '--permission-mode', 'bypassPermissions',
            '--output-format', 'json',
            '--print', agentTask
          ];
          break;
        case 'cursor-cli':
          agentCommand = 'cursor-agent';
          agentArgs = ['--force', agentTask];
          break;
        case 'codex-cli':
          agentCommand = 'codex';
          agentArgs = ['exec', '--dangerously-bypass-approvals-and-sandbox', '--json', agentTask];
          break;
        default:
          throw new Error(`Unknown eval agent: ${evalAgent}`);
      }

      console.log(`  Running: ${agentCommand} ${agentArgs.slice(0, 3).join(' ')}...`);

      const evalResult = spawnSync(agentCommand, agentArgs, {
        cwd: outputDir,
        encoding: 'utf8',
        stdio: 'pipe',
        timeout: 300000 // 5 minutes
      });

      if (evalResult.error) {
        throw new Error(`Failed to run ${evalAgent}: ${evalResult.error.message}`);
      }

      // Save raw output
      writeFileSync(join(outputDir, 'eval-agent-output.txt'), evalResult.stdout + '\n\n' + evalResult.stderr);

      // Try to parse JSON from output
      let evaluationData;
      try {
        // For claude-code with --output-format json, response is in stdout
        // For other agents, might need to extract from different places
        const output = evalResult.stdout.trim();

        // Try to find JSON in the output (might have other text around it)
        const jsonMatch = output.match(/\{[\s\S]*\}/);
        if (jsonMatch) {
          evaluationData = JSON.parse(jsonMatch[0]);
        } else {
          evaluationData = JSON.parse(output);
        }

        console.log('  ✓ Received evaluation from agent\n');

        // Validate structure
        if (evaluationData.by_priority) {
          results.by_priority = evaluationData.by_priority;
        }
        if (evaluationData.overall_notes) {
          results.overall_notes = evaluationData.overall_notes;
        }

        // Save parsed evaluation
        writeFileSync(join(outputDir, 'eval-agent-response.json'), JSON.stringify(evaluationData, null, 2));

      } catch (parseError) {
        console.log(`  ⚠ Could not parse agent response as JSON: ${parseError.message}`);
        console.log('  Creating placeholder results instead\n');

        // Fall back to placeholder results
        for (const criterion of criteria) {
          const priority = criterion.priority || 'medium';

          if (!results.by_priority[priority]) {
            results.by_priority[priority] = {};
          }

          results.by_priority[priority][criterion.name] = {
            strengths: ['[Could not parse agent response]'],
            issues: [],
            notes: [`Agent output saved to eval-agent-output.txt`, `Criterion: ${criterion.description}`]
          };
        }

        results.overall_notes.push(`Note: Agent response could not be parsed. See eval-agent-output.txt for raw output.`);
      }

    } catch (error) {
      console.log(`  ✗ Error running eval agent: ${error.message}\n`);

      // Create placeholder results
      for (const criterion of criteria) {
        const priority = criterion.priority || 'medium';

        if (!results.by_priority[priority]) {
          results.by_priority[priority] = {};
        }

        results.by_priority[priority][criterion.name] = {
          strengths: [],
          issues: [`Evaluation agent failed: ${error.message}`],
          notes: [`Criterion: ${criterion.description}`]
        };
      }

      results.overall_notes.push(`Error: Could not run evaluation agent - ${error.message}`);
    }

  } catch (error) {
    console.log(`  ✗ Error in non-deterministic evaluation: ${error.message}`);
    results.overall_notes.push(`Error during evaluation: ${error.message}`);
  }

  return results;
}

/**
 * Build evaluation prompt for LLM
 */
function buildEvaluationPrompt(outputDir, testDef, criteria) {
  let prompt = `# Agent Skills Test Evaluation

You are evaluating the results of an agent skills test. Your task is to assess the agent's performance based on the non-deterministic criteria defined for this test.

## Test Information

**Test Name:** ${testDef.name}
**Description:** ${testDef.description || 'N/A'}
**Task:** ${testDef.task}

## Evaluation Criteria

You will evaluate the following criteria, organized by priority:

`;

  // Group criteria by priority
  const byPriority = { high: [], medium: [], low: [] };
  for (const criterion of criteria) {
    const priority = criterion.priority || 'medium';
    byPriority[priority].push(criterion);
  }

  for (const priority of ['high', 'medium', 'low']) {
    if (byPriority[priority].length > 0) {
      prompt += `### ${priority.toUpperCase()} Priority\n\n`;
      for (const criterion of byPriority[priority]) {
        prompt += `- **${criterion.name}**: ${criterion.description}\n`;
      }
      prompt += '\n';
    }
  }

  prompt += `## Artifacts to Review

The following artifacts are available in the output directory:

`;

  // List available artifacts
  try {
    const files = readdirSync(outputDir);
    const relevantFiles = files.filter(f => {
      return f.endsWith('.js') || f.endsWith('.css') || f.endsWith('.json') ||
             f.endsWith('.md') || f.endsWith('.diff') || f === 'agent-info.json';
    });

    for (const file of relevantFiles) {
      prompt += `- ${file}\n`;
    }
  } catch (error) {
    prompt += '- (Error listing files)\n';
  }

  prompt += `
## Your Task

For each criterion, provide:

1. **Strengths**: What went well? What did the agent do correctly?
2. **Issues**: What didn't go well? What could be improved?
3. **Notes**: Additional observations or context

Also provide **Overall Notes** with general observations about the agent's performance.

## Important Guidelines

- Focus on qualitative assessment, not scores
- Consider the specific task and context
- Acknowledge that there may be multiple valid approaches
- Note both successes and areas for improvement
- Be constructive and specific in your feedback

## Output Format

Organize your findings by priority (high/medium/low), with each criterion having:
- strengths: array of strings
- issues: array of strings
- notes: array of strings

Plus overall_notes as an array of general observations.
`;

  return prompt;
}

/**
 * Generate evaluation outputs
 */
function generateOutputs(outputDir, evaluationResults) {
  console.log('\n=== Generating Evaluation Outputs ===\n');

  const timestamp = new Date().toISOString();

  // Generate JSON output
  const jsonOutput = {
    ...evaluationResults,
    timestamp,
    version: '1.0.0'
  };

  const jsonPath = join(outputDir, 'evaluation-results.json');
  writeFileSync(jsonPath, JSON.stringify(jsonOutput, null, 2));
  console.log(`  ✓ Saved JSON: ${jsonPath}`);

  // Generate Markdown report
  const mdContent = generateMarkdownReport(evaluationResults);
  const mdPath = join(outputDir, 'evaluation-report.md');
  writeFileSync(mdPath, mdContent);
  console.log(`  ✓ Saved report: ${mdPath}`);

  return { jsonPath, mdPath };
}

/**
 * Generate markdown report
 */
function generateMarkdownReport(results) {
  let md = '# Evaluation Report\n\n';

  md += `**Timestamp:** ${new Date().toISOString()}\n\n`;
  md += `**Test:** ${results.test_name || 'Unknown'}\n\n`;
  md += `**Agent:** ${results.agent || 'Unknown'}\n\n`;

  md += '## Deterministic Results\n\n';
  md += `**Status:** ${results.deterministic_results?.passed ? '✅ PASSED' : '❌ FAILED'}\n\n`;

  // Show all checks that were run
  if (results.deterministic_results?.checks) {
    md += '### Checks Run\n\n';
    const checks = results.deterministic_results.checks;
    for (const [checkName, passed] of Object.entries(checks)) {
      const icon = passed ? '✅' : '❌';
      md += `- ${icon} ${checkName}\n`;
    }
    md += '\n';
  }

  if (results.deterministic_results?.failures?.length > 0) {
    md += '### Failures\n\n';
    for (const failure of results.deterministic_results.failures) {
      md += `- ❌ ${failure}\n`;
    }
    md += '\n';
  }

  // Show optional checks that were run
  if (results.optional_results?.checks && Object.keys(results.optional_results.checks).length > 0) {
    md += '### Optional Checks\n\n';
    const checks = results.optional_results.checks;
    for (const [checkName, passed] of Object.entries(checks)) {
      const icon = passed ? '✅' : '⚠️';
      md += `- ${icon} ${checkName}\n`;
    }
    md += '\n';
  }

  if (results.optional_results?.warnings?.length > 0) {
    md += '### Warnings\n\n';
    for (const warning of results.optional_results.warnings) {
      md += `- ⚠️ ${warning}\n`;
    }
    md += '\n';
  }

  // Show PR results if PR was opened
  if (results.pr_results?.pr_opened) {
    md += '### Pull Request\n\n';
    md += `**URL:** ${results.pr_results.pr_url}\n\n`;
    if (results.pr_results.pr_quality && Object.keys(results.pr_results.pr_quality).length > 0) {
      md += '**Quality Checks:**\n\n';
      for (const [check, result] of Object.entries(results.pr_results.pr_quality)) {
        if (typeof result === 'boolean') {
          const icon = result ? '✅' : '❌';
          md += `- ${icon} ${check}\n`;
        } else if (check === 'preview_url') {
          md += `- Preview URL: ${result}\n`;
        }
      }
      md += '\n';
    }
    if (results.pr_results.failures?.length > 0) {
      md += '**PR Failures:**\n\n';
      for (const failure of results.pr_results.failures) {
        md += `- ❌ ${failure}\n`;
      }
      md += '\n';
    }
  }

  md += '## Non-Deterministic Criteria Assessment\n\n';

  if (results.non_deterministic_assessment && results.non_deterministic_assessment.by_priority) {
    const assessment = results.non_deterministic_assessment;

    for (const priority of ['high', 'medium', 'low']) {
      if (assessment.by_priority[priority] && Object.keys(assessment.by_priority[priority]).length > 0) {
        md += `### ${priority.toUpperCase()} Priority\n\n`;

        for (const [criterionName, criterionResults] of Object.entries(assessment.by_priority[priority])) {
          md += `#### ${criterionName}\n\n`;

          if (criterionResults.strengths && criterionResults.strengths.length > 0) {
            md += '**Strengths:**\n\n';
            criterionResults.strengths.forEach(s => md += `- ✅ ${s}\n`);
            md += '\n';
          }

          if (criterionResults.issues && criterionResults.issues.length > 0) {
            md += '**Issues:**\n\n';
            criterionResults.issues.forEach(i => md += `- ⚠️ ${i}\n`);
            md += '\n';
          }

          if (criterionResults.notes && criterionResults.notes.length > 0) {
            md += '**Notes:**\n\n';
            criterionResults.notes.forEach(n => md += `- ${n}\n`);
            md += '\n';
          }
        }
      }
    }

    if (assessment.overall_notes && assessment.overall_notes.length > 0) {
      md += '### Overall Notes\n\n';
      assessment.overall_notes.forEach(note => md += `- ${note}\n`);
      md += '\n';
    }

  } else {
    md += '_(Not evaluated)_\n\n';
  }

  return md;
}

/**
 * Evaluate a single agent's results
 */
async function evaluateSingleAgent(agentDir, testDef, options) {
  const pathParts = agentDir.split('/');
  const agent = pathParts[pathParts.length - 1];
  const testPath = pathParts.slice(pathParts.indexOf('test-results') + 1, -2).join('/');

  console.log(`\n${'='.repeat(60)}`);
  console.log(`Evaluating: ${agent}`);
  console.log('='.repeat(60));

  // Run evaluations
  const deterministic = await runDeterministicChecks(agentDir, testDef);
  const optional = await runOptionalChecks(agentDir, testDef);
  const prQuality = await checkPRQuality(agentDir, testDef);

  let nonDeterministic = null;
  if (!options.skipNonDeterministic) {
    nonDeterministic = await runNonDeterministicEvaluation(agentDir, testDef, options.evalAgent);
  } else {
    console.log('\n=== Skipping Non-Deterministic Evaluation ===\n');
  }

  // Combine results
  const evaluationResults = {
    test_name: testPath,
    test_definition_name: testDef.name,
    agent,
    deterministic_results: deterministic,
    optional_results: optional,
    pr_results: prQuality,
    non_deterministic_assessment: nonDeterministic
  };

  // Generate outputs
  const { jsonPath, mdPath } = generateOutputs(agentDir, evaluationResults);

  console.log(`\nStatus: ${deterministic.passed ? '✅ PASSED' : '❌ FAILED'}`);
  console.log(`Results saved to:`);
  console.log(`  - ${jsonPath}`);
  console.log(`  - ${mdPath}`);

  return {
    agent,
    passed: deterministic.passed,
    results: evaluationResults
  };
}

/**
 * Main execution
 */
async function main() {
  try {
    const options = parseArgs();

    console.log('='.repeat(60));
    console.log('Agent Skills Test Evaluation');
    console.log('='.repeat(60));
    console.log(`\nOutput Directory: ${options.outputDir}`);
    console.log(`Eval Agent: ${options.evalAgent}`);
    console.log(`Skip Non-Deterministic: ${options.skipNonDeterministic}`);

    // Load test definition
    console.log('\nLoading test definition...');
    const testDef = loadTestDefinition(options.outputDir);
    console.log(`Test: ${testDef.name}`);

    // Detect if we're evaluating one agent or all agents
    const pathType = detectPathType(options.outputDir);

    let agentResults = [];

    if (pathType === 'timestamp') {
      // Evaluate all agents in the timestamp directory
      const agentDirs = getAgentDirectories(options.outputDir);
      console.log(`\nFound ${agentDirs.length} agent(s) to evaluate`);

      for (const agentDir of agentDirs) {
        const result = await evaluateSingleAgent(agentDir, testDef, options);
        agentResults.push(result);
      }

      // Print summary
      console.log('\n' + '='.repeat(60));
      console.log('Evaluation Summary');
      console.log('='.repeat(60));
      for (const result of agentResults) {
        const status = result.passed ? '✅ PASSED' : '❌ FAILED';
        console.log(`  ${result.agent}: ${status}`);
      }

      // Exit with failure if any agent failed
      const allPassed = agentResults.every(r => r.passed);
      process.exit(allPassed ? 0 : 1);

    } else {
      // Evaluate single agent
      const result = await evaluateSingleAgent(options.outputDir, testDef, options);

      // Final summary
      console.log('\n' + '='.repeat(60));
      console.log('Evaluation Complete');
      console.log('='.repeat(60));

      // Exit with appropriate code
      process.exit(result.passed ? 0 : 1);
    }

  } catch (error) {
    console.error('\n❌ Error:', error.message);
    console.error(error.stack);
    process.exit(1);
  }
}

main();
